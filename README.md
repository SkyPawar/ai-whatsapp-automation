# AI WhatsApp & Email Automation System

A complete **AI-powered WhatsApp automation and admin dashboard system** built using **Python, Flask, Twilio WhatsApp API, ngrok, and Ollama (local LLM)**.

This project supports:
- Real-time WhatsApp AI auto-replies
- Admin dashboard with live chat
- Manual admin replies to WhatsApp users
- Local AI (no paid API, no rate limits)
- Secure environment variable handling

---

## ğŸš€ Features

- ğŸ¤– AI-based WhatsApp auto replies (local LLM via Ollama)
- ğŸ’¬ Admin dashboard with two-way chat
- ğŸ§‘â€ğŸ’¼ Manual admin replies sent to real WhatsApp users
- ğŸ“œ Conversation logging
- ğŸ”’ No API keys exposed on GitHub
- ğŸ’¸ Zero AI cost (runs locally)

---

## ğŸ›  Tech Stack

- **Backend:** Python, Flask  
- **AI:** Ollama (llama3 model â€“ local LLM)  
- **Messaging:** Twilio WhatsApp API  
- **Tunneling:** ngrok  
- **Frontend:** HTML, CSS (Flask Jinja templates)

---

````md
## ğŸ“ Project Structure

```text
ai-automation/
â”œâ”€â”€ admin/
â”‚   â””â”€â”€ dashboard.py
â”‚
â”œâ”€â”€ whatsapp/
â”‚   â””â”€â”€ webhook.py
â”‚
â”œâ”€â”€ ai/
â”‚   â””â”€â”€ reply_generator.py
â”‚
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ base.html
â”‚   â””â”€â”€ dashboard.html
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ css/
â”‚       â””â”€â”€ style.css
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ messages.log
â”‚
â”œâ”€â”€ config.py
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
```


---

## ğŸ” Environment Variables Setup (IMPORTANT)

Create a `.env` file in project root (this file is **NOT pushed to GitHub**):

```env
EMAIL_ID=your_email@gmail.com
EMAIL_PASSWORD=your_email_password

TWILIO_SID=ACxxxxxxxxxxxxxxxx
TWILIO_AUTH=xxxxxxxxxxxxxxxx
WHATSAPP_FROM=whatsapp:+14155238886
```
---

## ğŸ¤– Ollama (Local AI) Setup

This project uses Ollama to run AI locally (no OpenAI / paid APIs).

1ï¸âƒ£ Install Ollama
Download from:
ğŸ‘‰ https://ollama.com

- Restart your system after installation.

2ï¸âƒ£ Verify Ollama Installation
-> ollama --version

Expected output:
-> ollama version x.x.x

3ï¸âƒ£ Download AI Model (llama3)
-> ollama pull llama3

This downloads ~4.7GB model (one time only).

4ï¸âƒ£ Verify Ollama is Running
-> ollama list

Expected:
- llama3:latest

Test locally:
- ollama run llama3

Type:
- Hello

![alt text](image.png)

* If AI replies â†’ Ollama is working.

---

## ğŸŒ ngrok Setup (Expose Local Server)

- ngrok is used to expose your local Flask server to the internet so Twilio can reach it.

1ï¸âƒ£ Start Flask Server

From project root:
- python -m whatsapp.webhook

Flask runs on:
- http://127.0.0.1:5000

2ï¸âƒ£ Start ngrok Tunnel
In a new terminal:
- ngrok http 5000

You will see output like:
- Forwarding https://xxxx.ngrok-free.app -> http://localhost:5000

![alt text](image-1.png)

âœ… Copy the https ngrok URL
Example:
- https://1e16426d50b9.ngrok-free.app

--- 

## ğŸ“² Twilio WhatsApp Configuration

1ï¸âƒ£ Open Twilio Console
ğŸ‘‰ https://console.twilio.com

Go to:
- Messaging â†’ Try it out â†’ Send a WhatsApp message â†’ Sandbox settings

2ï¸âƒ£ Configure Webhook URL

In â€œWhen a message comes inâ€, set:
https://<ngrok-url>/whatsapp

Example:
https://1e16426d50b9.ngrok-free.app/whatsapp

Method: POST
Click Save

3ï¸âƒ£ Join WhatsApp Sandbox

From your personal WhatsApp, send:
join <your-code>

![alt text](image-2.png)

To the Twilio sandbox number:
+1 415 523 8886
(One-time step)

### ğŸ‘¨â€ğŸ’» Author
Sky Pawar - Software Developer